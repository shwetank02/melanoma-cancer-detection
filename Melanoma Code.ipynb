{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca8f9fe",
   "metadata": {},
   "source": [
    "# Step 1 : importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7266db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "np.random.seed(11) # It's my lucky number\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras import backend as K \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657323a7",
   "metadata": {},
   "source": [
    "# Step 2 : Loading pictures and making Dictionary of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a6c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_benign_train = '../input/data/train/benign'\n",
    "folder_malignant_train = '../input/data/train/malignant'\n",
    "\n",
    "folder_benign_test = '../input/data/test/benign'\n",
    "folder_malignant_test = '../input/data/test/malignant'\n",
    "\n",
    "read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
    "\n",
    "# Load in training pictures \n",
    "ims_benign = [read(os.path.join(folder_benign_train, filename)) for filename in os.listdir(folder_benign_train)]\n",
    "X_benign = np.array(ims_benign, dtype='uint8')\n",
    "ims_malignant = [read(os.path.join(folder_malignant_train, filename)) for filename in os.listdir(folder_malignant_train)]\n",
    "X_malignant = np.array(ims_malignant, dtype='uint8')\n",
    "\n",
    "# Load in testing pictures\n",
    "ims_benign = [read(os.path.join(folder_benign_test, filename)) for filename in os.listdir(folder_benign_test)]\n",
    "X_benign_test = np.array(ims_benign, dtype='uint8')\n",
    "ims_malignant = [read(os.path.join(folder_malignant_test, filename)) for filename in os.listdir(folder_malignant_test)]\n",
    "X_malignant_test = np.array(ims_malignant, dtype='uint8')\n",
    "\n",
    "# Create labels\n",
    "y_benign = np.zeros(X_benign.shape[0])\n",
    "y_malignant = np.ones(X_malignant.shape[0])\n",
    "\n",
    "y_benign_test = np.zeros(X_benign_test.shape[0])\n",
    "y_malignant_test = np.ones(X_malignant_test.shape[0])\n",
    "\n",
    "\n",
    "# Merge data \n",
    "X_train = np.concatenate((X_benign, X_malignant), axis = 0)\n",
    "y_train = np.concatenate((y_benign, y_malignant), axis = 0)\n",
    "\n",
    "X_test = np.concatenate((X_benign_test, X_malignant_test), axis = 0)\n",
    "y_test = np.concatenate((y_benign_test, y_malignant_test), axis = 0)\n",
    "\n",
    "# Shuffle data\n",
    "s = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_train = X_train[s]\n",
    "y_train = y_train[s]\n",
    "\n",
    "s = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_test = X_test[s]\n",
    "y_test = y_test[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0334d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=40\n",
    "h=30\n",
    "fig=plt.figure(figsize=(12, 8))\n",
    "columns = 5\n",
    "rows = 3\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    ax = fig.add_subplot(rows, columns, i)\n",
    "    if y_train[i] == 0:\n",
    "        ax.title.set_text('Benign')\n",
    "    else:\n",
    "        ax.title.set_text('Malignant')\n",
    "    plt.imshow(X_train[i], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85cc2fa",
   "metadata": {},
   "source": [
    "# Step 3: Categorical Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes= 2)\n",
    "y_test = to_categorical(y_test, num_classes= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2029bd",
   "metadata": {},
   "source": [
    "# Step 4 : Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b00bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting \n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4cf9a5",
   "metadata": {},
   "source": [
    "# Step 5: Model CNN Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4711813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See learning curve and validation curve\n",
    "\n",
    "def build(input_shape= (224,224,3), lr = 1e-3, num_classes= 2,\n",
    "          init= 'normal', activ= 'relu', optim= 'adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same',input_shape=input_shape,\n",
    "                     activation= activ, kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same', \n",
    "                     activation =activ, kernel_initializer = 'glorot_uniform'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    if optim == 'rmsprop':\n",
    "        optimizer = RMSprop(lr=lr)\n",
    "\n",
    "    else:\n",
    "        optimizer = Adam(lr=lr)\n",
    "\n",
    "    model.compile(optimizer = optimizer ,loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=5, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=1e-7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc904058",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "lr = 1e-5\n",
    "init = 'normal'\n",
    "activ = 'relu'\n",
    "optim = 'adam'\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "model = build(lr=lr, init= init, activ= activ, optim=optim, input_shape= input_shape)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2,\n",
    "                    epochs= epochs, batch_size= batch_size, verbose=0, \n",
    "                    callbacks=[learning_rate_reduction]\n",
    "                   )\n",
    "                   \n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])A\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39306b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "del model\n",
    "del history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32521c68",
   "metadata": {},
   "source": [
    "# Step 6: Cross-Validating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67be906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 3-fold cross validation test harness\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=11)\n",
    "\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "  # create model\n",
    "    model = build(lr=lr, \n",
    "                  init= init, \n",
    "                  activ= activ, \n",
    "                  optim=optim, \n",
    "                  input_shape= input_shape)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train[train], y_train[train], epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    K.clear_session()\n",
    "    del model\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbc6909",
   "metadata": {},
   "source": [
    "# Step 7: Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156135c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model to all data\n",
    "model = build(lr=lr, \n",
    "              init= init, \n",
    "              activ= activ, \n",
    "              optim=optim, \n",
    "              input_shape= input_shape)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=epochs, batch_size= batch_size, verbose=0,\n",
    "          callbacks=[learning_rate_reduction]\n",
    "         )\n",
    "\n",
    "# Testing model on test data to evaluate\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "print(accuracy_score(np.argmax(y_test, axis=1),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33504d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# Clear memory, because of memory overload\n",
    "del model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d253c9",
   "metadata": {},
   "source": [
    "# Step 8: Using ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7218f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "lr = 1e-5\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "model = ResNet50(include_top=True,\n",
    "                 weights= None,\n",
    "                 input_tensor=None,\n",
    "                 input_shape=input_shape,\n",
    "                 pooling='avg',\n",
    "                 classes=2)\n",
    "\n",
    "model.compile(optimizer = Adam(lr) ,\n",
    "              loss = \"binary_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2,\n",
    "                    epochs= epochs, batch_size= batch_size, verbose=2, \n",
    "                    callbacks=[learning_rate_reduction]\n",
    "                   )\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4311d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet50 on all the data\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=epochs, batch_size= epochs, verbose=0,\n",
    "          callbacks=[learning_rate_reduction]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model on test data to evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))\n",
    "\n",
    "# save model as hdf5\n",
    "model.save(\"resnet50model.hdf5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8680b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06808413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d594916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17804dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

